<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>LLaMA on Star5o的博客</title>
    <link>https://yakaili.github.io/zh-cn/tags/llama/</link>
    <description>Recent content in LLaMA on Star5o的博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>Star5o Love Haohao</copyright>
    <lastBuildDate>Wed, 07 Jun 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://yakaili.github.io/zh-cn/tags/llama/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Docker安装使用gpt-llama.cpp的LLM自主代理Auto-GPT</title>
      <link>https://yakaili.github.io/zh-cn/post/2023/06/07/install-autogpt-in-docker-with-llama.cpp/</link>
      <pubDate>Wed, 07 Jun 2023 00:00:00 +0000</pubDate>
      
      <guid>https://yakaili.github.io/zh-cn/post/2023/06/07/install-autogpt-in-docker-with-llama.cpp/</guid>
      <description>创建容器 1 2 3 4 5 6 7 8 9 10 11 12 docker pull nvidia/cuda:12.1.1-cudnn8-devel-ubuntu20.04 docker run --gpus all -it -d --name autollama -v /home/star5o/LLMs/:/LLMs/ --ipc=host -p 8000:8000 nvidia/cuda:12.1.1-cudnn8-devel-ubuntu20.04 /bin/bash #进入容器 docker exec -it autollama bash cd /LLMs # 更新源 apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/3bf863cc.pub apt update 下载并配置llama.cpp项目 配置llama.cpp项目主要是为了验证模型权重是否能正</description>
    </item>
    
    <item>
      <title>本地安装使用gpt-llama.cpp的LLM自主代理Auto-GPT</title>
      <link>https://yakaili.github.io/zh-cn/post/2023/06/07/install-autogpt-in-local-with-llama.cpp/</link>
      <pubDate>Wed, 07 Jun 2023 00:00:00 +0000</pubDate>
      
      <guid>https://yakaili.github.io/zh-cn/post/2023/06/07/install-autogpt-in-local-with-llama.cpp/</guid>
      <description>下载并配置llama.cpp项目 下载llama.cpp项目 1 git clone https://github.com/ggerganov/llama.cpp &amp;amp;&amp;amp; cd llama.cpp 下载LLaMa权重文件 根据脚本https://github.com/Elyah2035/llama-dl使用以下磁力链接下载： 1</description>
    </item>
    
    <item>
      <title>通过docker安装LLM自主代理babyagi</title>
      <link>https://yakaili.github.io/zh-cn/post/2023/06/06/install-babyagi-in-docker/</link>
      <pubDate>Tue, 06 Jun 2023 00:00:00 +0000</pubDate>
      
      <guid>https://yakaili.github.io/zh-cn/post/2023/06/06/install-babyagi-in-docker/</guid>
      <description>获取Pinecone API密钥 Pinecone是一个用于存储AI数据的矢量数据库。通过点击API密钥标签，点击复制按钮或 “Create API Key” 来获得API密钥。另外，注意 “Environment” 的</description>
    </item>
    
  </channel>
</rss>
